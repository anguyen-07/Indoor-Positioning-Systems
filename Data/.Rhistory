plotts.wge(fit1$residuals)
ltest1=ljung.wge(fit1$residuals)
ltest1$pval
data$Zt_L2 = dplyr::lag(data$Zt,5)
ksfit2=lm(Xt~Zt_L2, data=data)
phi2=aic.wge(ksfit2$residuals,p=0:10, q=0:5)
fit2=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt)
fit2
plotts.wge(fit2$residuals)
ltest2=ljung.wge(fit2$residuals)
ltest2$pval
ksfit=lm(Xt~Zt, data=data)
phi=aic.wge(ksfit$residuals,p=0:10, q=0:5)
fit=arima(data$Xt, order=c(phi$p,0,phi$q),xreg=data$Zt)
fit
plotts.wge(fit$residuals)
ltest=ljung.wge(fit$residuals)
ltest$pval
data$Zt_L1 = dplyr::lag(data$Zt,1)
ksfit1=lm(Xt~Zt_L1, data=data)
phi1=aic.wge(ksfit1$residuals,p=0:10, q=0:5)
fit1=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt_L1)
fit1
plotts.wge(fit1$residuals)
ltest1=ljung.wge(fit1$residuals)
ltest1$pval
data$Zt_L2 = dplyr::lag(data$Zt,2)
ksfit2=lm(Xt~Zt_L2, data=data)
phi2=aic.wge(ksfit2$residuals,p=0:10, q=0:5)
fit2=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt_L2)
fit2
plotts.wge(fit2$residuals)
ltest2=ljung.wge(fit2$residuals)
ltest2$pval
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt_L1[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(X, type= "trend") #AIC selects p=5
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(dplyr)
data = read.csv('C:/Users/micha/OneDrive/Desktop/FinalExamData.csv', header=TRUE)
data = subset(data, select=c(Xt,Zt))
head(data)
ksfit=lm(Xt~Zt, data=data)
phi=aic.wge(ksfit$residuals,p=0:10, q=0:5)
fit=arima(data$Xt, order=c(phi$p,0,phi$q),xreg=data$Zt)
fit
plotts.wge(fit$residuals)
ltest=ljung.wge(fit$residuals)
ltest$pval
data$Zt_L1 = dplyr::lag(data$Zt,1)
ksfit1=lm(Xt~Zt_L1, data=data)
phi1=aic.wge(ksfit1$residuals,p=0:10, q=0:5)
fit1=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt_L1)
fit1
plotts.wge(fit1$residuals)
ltest1=ljung.wge(fit1$residuals)
ltest1$pval
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt_L1[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(X, type= "trend") #AIC selects p=5
library(vars)
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt_L1[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(X, type= "trend") #AIC selects p=5
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(X, type= "trend") #AIC selects p=5
#VARfit = VAR(X, p=5, type = "trend", s = 52)
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=5
#VARfit = VAR(X, p=5, type = "trend", s = 52)
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(Xt.X, p=6, type = "trend")
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
#ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$FluCases.X[1:12,1])^2) # 125,585,906
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt_L1[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
#ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$FluCases.X[1:12,1])^2) # 125,585,906
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$Xt.X[1:10,1])^2) # 125,585,906
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$Xt.X[1:10,1])^2) # 125,585,906
ASE.VAR
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
library(nnfor)
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 12, xreg = t)
?mlp
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) # 1,959,621.28
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
#TS.fluX = data.frame(A_H1N1, A_H3N2, B, B_Yam, B_Vic)
NN.multi.fit = mlp(Xt.X, xreg=Zt.X, hd=5, reps=20)
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.09684
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
#TS.fluX = data.frame(A_H1N1, A_H3N2, B, B_Yam, B_Vic)
NN.multi.fit = mlp(Xt.X, xreg=data$Zt_L1, hd=5, reps=20)
?mlp4
?mlp
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.09684
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
#TS.fluX = data.frame(A_H1N1, A_H3N2, B, B_Yam, B_Vic)
NN.multi.fit = mlp(Xt.X, xreg=data$Zt, hd=5, reps=20)
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.09684
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, Zt.X)
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.09684
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, data$Zt)
NN.multi.fit = mlp(Xt.X, xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
ASE.NN.multi = mean((FluCases[219:230] - f.NN.multi$mean)^2) # 2,717,874.75
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.09684
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, data$Zt)
NN.multi.fit = mlp(Xt.X, xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
ASE.NN.multi = mean((data$Xt[86:95] - f.NN.multi$mean)^2) # 2,717,874.75
NN.multi.fit
plot(NN.multi.fit)
ASE.NN.multi
ksfit=lm(Xt~Zt, data=data)
phi=aic.wge(ksfit$residuals,p=0:10, q=0:5)
fit=arima(data$Xt, order=c(phi$p,0,phi$q),xreg=data$Zt)
fit
plotts.wge(fit$residuals)
ltest=ljung.wge(fit$residuals)
ltest$pval
data$Zt_L5 = dplyr::lag(data$Zt,5)
ksfit5=lm(Xt~Zt_L5, data=data)
phi5=aic.wge(ksfit5$residuals,p=0:10, q=0:5)
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(dplyr)
library(vars)
library(nnfor)
data = read.csv('C:/Users/micha/OneDrive/Desktop/FinalExamData.csv', header=TRUE)
data = subset(data, select=c(Xt,Zt))
head(data)
ksfit=lm(Xt~Zt, data=data)
phi=aic.wge(ksfit$residuals,p=0:10, q=0:5)
fit=arima(data$Xt, order=c(phi$p,0,phi$q),xreg=data$Zt)
fit
plotts.wge(fit$residuals)
ltest=ljung.wge(fit$residuals)
ltest$pval
data$Zt_L5 = dplyr::lag(data$Zt,5)
ksfit5=lm(Xt~Zt_L5, data=data)
phi5=aic.wge(ksfit5$residuals,p=0:10, q=0:5)
fit5=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt_L5)
fit5
plotts.wge(fit5$residuals)
ltest5=ljung.wge(fit5$residuals)
ltest5$pval
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$Xt.X[1:10,1])^2) #20.283
ASE.VAR
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.097
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, data$Zt)
NN.multi.fit = mlp(Xt.X, xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
ASE.NN.multi = mean((data$Xt[86:95] - f.NN.multi$mean)^2) #18.336
NN.multi.fit
plot(NN.multi.fit)
ASE.NN.multi
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt_L5[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$Xt.X[1:10,1])^2) #20.283
ASE.VAR
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.097
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, data$Zt)
NN.multi.fit = mlp(Xt.X, xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
ASE.NN.multi = mean((data$Xt[86:95] - f.NN.multi$mean)^2) #18.336
NN.multi.fit
plot(NN.multi.fit)
ASE.NN.multi
ensemble = (VAR.preds$fcst$Xt.X[,1] + f.NN.multi$mean)/2
ensemble = mean((data$Xt[86:95] - ensemble)^2) # 1,768,538
plot(data[1:95], type = "l")
ensemble = (VAR.preds$fcst$Xt.X[,1] + f.NN.multi$mean)/2
ensemble = mean((data$Xt[86:95] - ensemble)^2) # 1,768,538
plot(data$Xt[1:95], type = "l")
lines(seq(86,95,1), ensemble, col = "blue", lwd = 2)
ensemble = (VAR.preds$fcst$Xt.X[,1] + f.NN.multi$mean)/2
ensemble.ASE = mean((data$Xt[86:95] - ensemble)^2) # 1,768,538
plot(data$Xt[1:95], type = "l")
lines(seq(86,95,1), ensemble, col = "blue", lwd = 2)
ensemble.ASE
plot(data$Xt[96:105], type = "l")
plot(data$Xt[96:105], type = "l", ylim = c(1500,6000))
lines(seq(1,10), ensemble.seas, col = "blue", lwd = 2)
plot(data$Xt[96:105], type = "l", ylim = c(1500,6000))
lines(seq(1,10), ensemble, col = "blue", lwd = 2)
plot(data$Xt[96:105], type = "l", ylim = c(0,100))
lines(seq(1,10), ensemble, col = "blue", lwd = 2)
plot(data$Xt[96:105], type = "l", ylim = c(0,100))
lines(seq(1,10), ensemble, col = "blue", lwd = 2)
ensemble
VARfit = VAR(data, p=6, type = "trend")
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.multi.fit = mlp(data$Xt, xreg=TS.X, hd=5, reps=20)
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.multi.fit = mlp(ts(data$Xt), xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
t = data.frame(ts(1:105))
TS.X = data.frame(t, data$Zt)
ensemble = (VAR.preds$fcst$Xt.X[,1] + f.NN.uni$mean)/2
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(dplyr)
library(vars)
library(nnfor)
data = read.csv('C:/Users/micha/OneDrive/Desktop/FinalExamData.csv', header=TRUE)
data = subset(data, select=c(Xt,Zt))
head(data)
ksfit=lm(Xt~Zt, data=data)
phi=aic.wge(ksfit$residuals,p=0:10, q=0:5)
fit=arima(data$Xt, order=c(phi$p,0,phi$q),xreg=data$Zt)
fit
plotts.wge(fit$residuals)
ltest=ljung.wge(fit$residuals)
ltest$pval
data$Zt_L5 = dplyr::lag(data$Zt,5)
ksfit5=lm(Xt~Zt_L5, data=data)
phi5=aic.wge(ksfit5$residuals,p=0:10, q=0:5)
fit5=arima(data$Xt, order=c(phi1$p,0,phi1$q),xreg=data$Zt_L5)
fit5
plotts.wge(fit5$residuals)
ltest5=ljung.wge(fit5$residuals)
ltest5$pval
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
VARselect(Xt.X, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[86:95] - VAR.preds$fcst$Xt.X[1:10,1])^2) #20.283
ASE.VAR
#Univariate Neural Network
t = data.frame(ts(1:95))
NN.uni.fit = mlp(Xt.X, xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, h = 10, xreg = t)
ASE.NN.uni = mean((data$Xt[86:95] - f.NN.uni$mean)^2) #21.097
NN.uni.fit
plot(NN.uni.fit)
ASE.NN.uni
# Multivariate Neural Network
TS.X = data.frame(t, data$Zt)
NN.multi.fit = mlp(Xt.X, xreg=TS.X, hd=5, reps=20)
f.NN.multi = forecast(NN.multi.fit, xreg=TS.X, h=10)
ASE.NN.multi = mean((data$Xt[86:95] - f.NN.multi$mean)^2) #18.336
NN.multi.fit
plot(NN.multi.fit)
ASE.NN.multi
ensemble = (VAR.preds$fcst$Xt.X[,1] + f.NN.uni$mean)/2
ensemble.ASE = mean((data$Xt[86:95] - ensemble)^2) # 1,768,538
plot(data$Xt[1:95], type = "l")
lines(seq(86,95,1), ensemble, col = "blue", lwd = 2)
ensemble.ASE
t = data.frame(ts(1:105))
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.uni.fit = mlp(ts(data$Xt), xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, xreg=TS.X, h=10)
t = data.frame(ts(1:105))
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.uni.fit = mlp(ts(data$Xt), xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, xreg=t, h=10)
ensemble.fore = (VAR.preds$fcst$Xt.X[,1] + f.NN.multi$mean)/2
t = data.frame(ts(1:105))
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.uni.fit = mlp(ts(data$Xt), xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, xreg=t, h=10)
ensemble.fore = (VAR.preds$fcst$Xt.X[,1] + f.NN.uni$mean)/2
t = data.frame(ts(1:105))
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.uni.fit = mlp(ts(data$Xt), xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, xreg=t, h=10)
ensemble.fore = (VAR.preds$fcst$Xt[,1] + f.NN.uni$mean)/2
VAR.preds$fcst$Xt
VAR.preds$fcst$y1
t = data.frame(ts(1:105))
X = cbind(data$Xt, data$Zt)
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
NN.uni.fit = mlp(ts(data$Xt), xreg=t, hd=5, reps=20)
f.NN.uni = forecast(NN.uni.fit, xreg=t, h=10)
ensemble.fore = (VAR.preds$fcst$y1[,1] + f.NN.uni$mean)/2
plot(data$Xt[96:105], type = "l", ylim = c(0,100))
lines(seq(1,10), ensemble, col = "blue", lwd = 2)
ensemble.fore
trainingSize = 33
horizon = 10
ASEHolder.UNN = numeric()
ASEHolder.VAR = numeric()
Xt.X = ts(data$Xt[1:85])
Zt.X = ts(data$Zt[1:85])
X = cbind(Xt.X, Zt.X)
t = data.frame(ts(1:95))
for( i in 1:(95 - (trainingSize + horizon) + 1))
{
Xt.train = ts(data$Xt[i:(i+(trainingSize-1))])
uniNN.fit = mlp(Xt.train, xreg = t, hd = 5, reps = 20)
f.uniNN = forecast(uniNN.fit, h = 10, xreg = t)
ASE.uniNN = mean((data$Xt[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - f.uniNN$mean)^2)
ASEHolder.UNN[i] = ASE.uniNN
VARselect(Xt.train, type= "trend") #AIC selects p=6
VARfit = VAR(X, p=6, type = "trend")
VAR.preds = predict(VARfit, n.ahead = 10)
ASE.VAR = mean((data$Xt[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - VAR.preds$fcst$Xt.X[1:10,1])^2)
ASEHolder.VAR[i] = ASE.VAR
}
ASEHolder.UNN
mean(ASEHolder.UNN)
mean(ASEHolder.VAR)
setwd("C:/Users/micha/QTW-CaseStudy1/Data")
write.csv(offline, file = 'offlineOutput.csv')
write.csv(online, file = 'onlineOutput.csv')
#offline = processData("http://rdatasciencecases.org/Data/offline.final.trace.txt")
online = processData("http://rdatasciencecases.org/Data/online.final.trace.txt")
# Save Processed data into csv that can be read into python as a pandas dataframe
#write.csv(offline, file = 'offlineOutput.csv')
write.csv(online, file = 'onlineOutput.csv')
# Save Processed data into csv that can be read into python as a pandas dataframe
#write.csv(offline, file = 'offlineOutput.csv')
write.csv(online, file = 'onlineOutput.csv')
library(tidyverse)
library(magrittr)
# Parser Function that returns matricies of measured signal strengths
processLine =
function(x) {
tokens = strsplit(x, "[;=,]")[[1]]
if (length(tokens) == 10)
return(NULL)
tmp = matrix(tokens[ - (1:10) ], , 4, byrow = TRUE)
cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6,
byrow = TRUE), tmp)
}
roundOrientation =
function(angles) {
refs = seq(0, by = 45, length = 9)
q = sapply(angles, function(o) which.min(abs(o - refs)))
c(refs[1:8], 0)[q]
}
processData =
function(filename)
{ # read in data from file
txt = readLines(filename)
# subset original offline text data to remove all lines with comments
lines = txt[ substr(txt, 1, 1) != "#" ]
# apply parser function to every line in the text file
tmp = lapply(lines, processLine)
# cast parsed data into data frame
offline = as.data.frame(do.call("rbind", tmp),
stringsAsFactors= FALSE)
# assign variable names to data features
names(offline) = c("time", "scanMac",
"posX", "posY", "posZ", "orientation",
"mac", "signal", "channel", "type")
# Remove all adhoc type measurements from data frame
# Analysis will only include signal strengths measured to fixed access points
offline = offline[ offline$type == "3", ]
# Drop scanMac, posZ, channel, and type (contain no useful info)
# only 1 value for scanMac, the MAC for the hand-held device
# posZ = 0 for all measurements since they were all taken on the same floor
dropVars = c("scanMac", "posZ", "channel", "type")
offline = offline[ , !( names(offline) %in% dropVars ) ]
# There are 12 unqiue MAC addresses and 8 channels
# keep records from top 7 devices, since there is a large drop in number of signals after (>100,000)
# channels removed b/c one-to-one correspondence between MAC addresses and channels for remaining 7 devices
keepMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7]
offline = offline[ offline$mac %in% keepMacs, ]
# # convert attributes to appropriate data types (numeric)
numVars = c("time", "posX", "posY", "orientation", "signal")
offline[ numVars ] = lapply(offline[ numVars ], as.numeric)
# Format time to POSIXt - change scale from milliseconds to seconds
offline$rawTime = offline$time
offline$time = offline$time/1000
class(offline$time) = c("POSIXt", "POSIXct")
# Round orientations to nearest 45 degree increment
offline$orientation = roundOrientation(offline$orientation)
return(offline)
}
#offline = processData("http://rdatasciencecases.org/Data/offline.final.trace.txt")
online = processData("http://rdatasciencecases.org/Data/online.final.trace.txt")
# Save Processed data into csv that can be read into python as a pandas dataframe
#write.csv(offline, file = 'offlineOutput.csv')
write.csv(online, file = 'onlineOutput.csv')
